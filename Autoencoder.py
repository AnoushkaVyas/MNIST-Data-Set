# -*- coding: utf-8 -*-
"""q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yGFK7rKU1PCGDIw46-xZQoaCbEu2knLB
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import torch.nn.init as weight_init
import matplotlib.pyplot as plt
import pdb


#parameters
batch_size = 128

preprocess = transforms.Compose([
                           transforms.ToTensor(),
                           transforms.Normalize((0.1307,), (0.3081,))
                       ])

#Loading the train set file
dataset = datasets.MNIST(root='./data',
                            transform=preprocess,  
                            download=True)

loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)

class AE(nn.Module):
    def __init__(self,hh):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(28*28, 256),
            nn.ReLU(),
            nn.Linear(256,64),
            nn.ReLU(),
            nn.Linear(64,hh),
        )
        self.decoder = nn.Sequential(
            nn.Linear(hh, 64),
            nn.ReLU(),
            nn.Linear(64, 256),
            nn.ReLU(),
            nn.Linear(256, 28*28),
            nn.Tanh()
        )
    
    def forward(self,x):
        h = self.encoder(x)
        xr = self.decoder(h)
        return xr,h

use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
print('Using CUDA ', use_cuda)



#Mean square loss function
criterion = nn.MSELoss()

#Parameters
learning_rate = 1e-2
weight_decay = 1e-5

num_epochs = 5
hh=[2,7,10,14,20,24]
#Training
Loss=[]
for i in range(6):
  net = AE(hh[i])
  net = net.to(device)
  optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=weight_decay, amsgrad=False)
  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, threshold=0.001, patience=5, verbose = True)  
  for epoch in range(num_epochs):
      total_loss, cntr = 0, 0
      
      for i,(images,_) in enumerate(loader):
          
          images = images.view(-1, 28*28)
          images = images.to(device)
          
          # Initialize gradients to 0
          optimizer.zero_grad()
          
          # Forward pass (this calls the "forward" function within Net)
          outputs, _ = net(images)
          
          # Find the loss
          loss = criterion(outputs, images)
          
          # Find the gradients of all weights using the loss
          loss.backward()
          
          # Update the weights using the optimizer and scheduler
          optimizer.step()
        
          total_loss += loss.item()
          cntr += 1
      
      scheduler.step(total_loss/cntr)
  Loss.append(total_loss/cntr)

plt.scatter(hh,Loss)
plt.title('Adam')
plt.plot()